{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1870c1ad-c954-4460-86a3-601416df2c02",
   "metadata": {},
   "source": [
    "Tento notebook slouží k **ověření, že máte nainstalované potřebné knihovny** a že vám funguje připojení k webovým stránkám.\n",
    "\n",
    "**Prosím spusťte všechny buňky postupně a ověřte, že vám vše funguje.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09b08fa-b870-4acb-b1c8-c20caa7deed2",
   "metadata": {},
   "source": [
    "# Session 4 - Uvod do Web Scrapingu\n",
    "\n",
    "V predchozich lekcich jsme se naucili ziskavat data z webovych stranek pomoci jejich API. Ne kazda stranka ma API - mnohe z nich byly vytvoreny s predpokladem, ze jejich obsah budou cist pouze lide. To ale neznamena, ze nelze tento obsah ziskat pomoci Pythonu - jen je potreba pouzit jine nastroje.\n",
    "\n",
    "**Web scraping** je technika pro stahovani a extrahovani informaci z webovych stranek. Sklada se z:\n",
    "1. Stazeni obsahu webove stranky (napr. pomoci knihovny `requests`)\n",
    "2. Transformace obsahu (stazeny obsah je jeden dlouhy retezec) do struktury, ve ktere se da lepe vyhledavat\n",
    "3. Extrakce potrebnych informaci\n",
    "\n",
    "V teto lekci se naucime:\n",
    "- Zaklady knihovny `requests` pro stahovani webovych stranek\n",
    "- Parsovani HTML pomoci `BeautifulSoup`\n",
    "- CSS selektory pro vyhledavani elementu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f764d02-c53e-4bab-b306-68e0a7100629",
   "metadata": {},
   "source": [
    "## Proc je web scraping obtizny?\n",
    "\n",
    "Ve srovnani se ziskavanim dat pres API ma web scraping vyznamne nevyhody:\n",
    "\n",
    "**1. Musite dobre znat strukturu stranky** - Neexistuje zadna dokumentace. Sami si musite zjistit, jak vypadaji odkazy a jak je obsah stranky rozlozen.\n",
    "\n",
    "**2. Data nejsou tak strukturovana jako v API** - Obsah stranky v HTML je podrizen tomu, jak ma stranka vypadat, ne tomu, jak se data snadno zpracuji.\n",
    "\n",
    "**3. Stranka se muze zmenit bez varovani** - Autor stranky nezarucuje, ze stranka bude vzdy vypadat stejne. Skript muze prestat fungovat a bude potrebovat opravy.\n",
    "\n",
    "**4. Stranka muze byt dynamicka** - JavaScript muze nacitat obsah az po nacteni stranky. V takovem pripade je potreba pouzit nastroje jako Selenium."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee0c0ee-6959-4de6-8fb8-7daff1a5c01e",
   "metadata": {},
   "source": [
    "## Struktura URL adresy\n",
    "\n",
    "Kazda webova stranka se nachazi na nejake adrese. Priklad:\n",
    "\n",
    "`http://host.name.eu:80/directory/index.html?param1=value1&param2=value2`\n",
    "\n",
    "Casti URL adresy:\n",
    "1. `http://` nebo `https://` - protokol (`https` je sifrovana verze `http`)\n",
    "2. `host.name.eu` - domenove jmeno serveru\n",
    "3. `:80` - cislo portu (vychozi: 80 pro http, 443 pro https)\n",
    "4. `/directory/index.html` - cesta k souboru na serveru\n",
    "5. `?param1=value1&param2=value2` - querystring: dodatecne parametry (zacinaji `?`, oddelene `&`)\n",
    "\n",
    "Priklad moderni URL: `https://example.com/article/2024/05/my-article?ref=newsletter`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8d1257-34c7-4e5d-9924-e5ea54dab376",
   "metadata": {},
   "source": [
    "## 1. Instalace knihovny\n",
    "Nejprve musime nainstalovat potrebne knihovny. Pouzijeme `pip` primo v notebooku.\n",
    "\n",
    "### Proc pouzivame vykricnik `!` ?\n",
    "\n",
    "V Jupyter notebooku se kod interpretuje jako Python. Pro prikazy prikazoveho radku (terminalu) pouzivame `!` na zacatku.\n",
    "\n",
    "```python\n",
    "print('Ahoj')       # Python kod - funguje primo\n",
    "!pip install requests  # Prikaz pro terminal - potrebuje !\n",
    "```\n",
    "\n",
    "### `!pip` vs `%pip`\n",
    "\n",
    "| Prikaz | Kam instaluje |\n",
    "|--------|---------------|\n",
    "| `!pip install` | Podle systemoveho PATH (muze byt jine prostredi) |\n",
    "| `%pip install` | Vzdy do prostredi aktualniho kernelu |\n",
    "\n",
    "Doporuceni: V Anaconde je bezpecnejsi pouzivat `%pip`, aby se balicek urcite nainstaloval do spravneho prostredi."
   ]
  },
  {
   "cell_type": "raw",
   "id": "05955f95-6c13-42c5-bcd6-0d1bd666776e",
   "metadata": {},
   "source": [
    "# Instalace knihovny BeautifulSoup (pro parsování HTML)\n",
    "%pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-test",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Test importu knihoven\n",
    "\n",
    "Pokud import proběhne bez chyby, knihovny jsou správně nainstalovány."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test-imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "print(\"Import knihoven proběhl úspěšně!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-bankier",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Test připojení - Bankier.pl\n",
    "\n",
    "Tento příklad ukazuje stažení stránky polské banky. Stránka byla **redesignována**, takže se na ni dostaneme (stavový kód 200), ale původní element `boxKursyNbpTab1` tam již není.\n",
    "\n",
    "**Očekávaný výsledek:** Stavový kód 200, ale 0 nalezených kurzů."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test-bankier",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test připojení k Bankier.pl\n",
    "website = requests.get('https://www.bankier.pl/waluty')\n",
    "\n",
    "print(f\"Stavový kód: {website.status_code}\")\n",
    "print(f\"Připojení úspěšné: {website.ok}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test-bankier-element",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hledáme element, který tam dříve byl (po redesignu už neexistuje)\n",
    "content = BeautifulSoup(website.text, 'html.parser')\n",
    "div_rates = content.find('div', id='boxKursyNbpTab1')\n",
    "\n",
    "if div_rates:\n",
    "    print(\"Element nalezen - stránka nebyla změněna.\")\n",
    "else:\n",
    "    print(\"Element NENALEZEN - stránka byla redesignována.\")\n",
    "    print(\"Toto je očekávané chování. Na lekci si ukážeme, proč k tomu dochází.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-quotes",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Test funkčního příkladu - Quotes to Scrape\n",
    "\n",
    "Tento příklad by měl fungovat správně. Stránka `quotes.toscrape.com` je speciálně vytvořená pro výuku webscrapingu.\n",
    "\n",
    "**Očekávaný výsledek:** Stavový kód 200, nalezeno 10 citátů."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test-quotes",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stažení stránky\n",
    "url = \"https://quotes.toscrape.com\"\n",
    "response = requests.get(url)\n",
    "\n",
    "print(f\"Stavový kód: {response.status_code}\")\n",
    "print(f\"Připojení úspěšné: {response.ok}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test-quotes-parse",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parsování a nalezení citátů\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "quotes = soup.find_all('div', class_='quote')\n",
    "\n",
    "print(f\"Nalezeno citátů: {len(quotes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test-quotes-display",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ukázka - zobrazení prvních 3 citátů\n",
    "for i, quote in enumerate(quotes[:3], 1):\n",
    "    text = quote.find('span', class_='text').text\n",
    "    author = quote.find('small', class_='author').text\n",
    "    \n",
    "    print(f\"{i}. {author}:\")\n",
    "    print(f\"   {text}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-summary",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Shrnutí\n",
    "\n",
    "Pokud jste viděli:\n",
    "\n",
    "- **Import proběhl úspěšně** ✓\n",
    "- **Bankier.pl: Stavový kód 200, element NENALEZEN** ✓\n",
    "- **Quotes: Stavový kód 200, nalezeno 10 citátů** ✓\n",
    "\n",
    "...pak je vše v pořádku a jste připraveni na lekci!\n",
    "\n",
    "Na lekci si vše projdeme detailně."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fac52f-3629-42fe-952c-1fd32b3100bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
