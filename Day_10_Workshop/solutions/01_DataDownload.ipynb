{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J0flaw7HdTLC"
   },
   "source": [
    "# Introduction\n",
    "\n",
    "The first step in our task is to obtain the data necessary for analysis. Since our company is in the early stages of development and does not have its own database, we intend to use publicly available resources.  \n",
    "  \n",
    "For this purpose, we have been recommended the website [Scrape This Site](https://www.scrapethissite.com/pages/forms/). However, before we start downloading data, it is important to carefully review the [FAQ](https://www.scrapethissite.com/faq/) section on the site. Particular attention should be paid to the restrictions on the number of requests, which is crucial for our solution.  \n",
    "  \n",
    "It is expected that after executing the code contained in this notebook, the `data/raw/` folder will be populated with data, which will serve as the source for the next stage of the project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3U3qrIFCdTLF"
   },
   "source": [
    "# Notebook Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V8i_DaiDdTLF"
   },
   "source": [
    "## Importing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "9ppX5CyndTLG"
   },
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.by import By\n",
    "from selenium import webdriver\n",
    "\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d7zC6meddTLG"
   },
   "source": [
    "## Driver and Selenium Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chrome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Firefox"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "browser = webdriver.Firefox()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Edge"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "browser = webdriver.Edge()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Opera"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Pro Operu - Opera pouziva ChromeDriver:\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "options = Options()\n",
    "options.binary_location = 'cesta k souboru .... opera.exe' # tu musíte nastavit cestu k souboru opera.exe\n",
    "browser = webdriver.Chrome(options=options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mgv7K-lQdTLG"
   },
   "source": [
    "# Fetching Website Content\n",
    "\n",
    "This section of the notebook contains code for fetching website content. To properly execute the task, consider the following steps:  \n",
    "- Ensure all available data on the site has been fetched by checking if there are additional data pages.  \n",
    "- Locate the data of interest on the page using `html` inspection tools.  \n",
    "- Navigate between subsequent data pages using browser mechanisms or by analyzing the `url` structure.  \n",
    "  \n",
    "> Remember to respect the query limits specified in the `FAQ`!  \n",
    "  \n",
    "Save the fetched data to the folder `data/raw/hockey_teams_page_{page_number}.html`. At this stage, we are retrieving data without processing it - analysis will be performed later.  \n",
    "  \n",
    "To fetch the `html` content of the page, you can use `browser.page_source`. Make sure the browser tool configuration (e.g., Selenium) is ready for use.  \n",
    "  \n",
    "> (Optional) If there are multiple pages to fetch, use the [zfill](https://www.programiz.com/python-programming/methods/string/zfill) function to maintain order in file names by adding leading zeros to the page numbers.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "lCOc6J3ldTLH"
   },
   "outputs": [],
   "source": [
    "def is_table_empty() -> bool:\n",
    "    \"\"\"\n",
    "    Sprawdza czy tabela na stronie nie zawiera żadnych danych\n",
    "\n",
    "    :return: True jeśli strona jest pusta, w przeciwnym wypadku False\n",
    "    \"\"\"\n",
    "    table_rows = (\n",
    "        browser\n",
    "        .find_element(by=By.TAG_NAME, value='table')\n",
    "        .find_elements(by=By.TAG_NAME, value='tr')\n",
    "    )\n",
    "\n",
    "    # w pustej tabeli dostępny jest tylko nagłówek\n",
    "    if len(table_rows)  == 1:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "RFOntlnnezWG"
   },
   "outputs": [],
   "source": [
    "per_page = 50\n",
    "browser.implicitly_wait(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Hauuq2p0ez7k"
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "url_template = 'https://www.scrapethissite.com/pages/forms/?page_num={page}'\n",
    "page = 1\n",
    "\n",
    "while True:\n",
    "    url = url_template.format(page=page, per_page=per_page)\n",
    "    browser.get(url)\n",
    "\n",
    "    html = browser.page_source\n",
    "    if is_table_empty():\n",
    "        break\n",
    "\n",
    "    page_number_str = str(page).zfill(2)\n",
    "    with open(f'../data/raw/hockey_teams_page_{page_number_str}.html', 'w') as file:\n",
    "        file.write(browser.page_source)\n",
    "\n",
    "    page += 1\n",
    "    sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ycm9QC8dTLH"
   },
   "source": [
    "# Summary\n",
    "\n",
    "Downloading raw data from our source has reduced the risk of problems stemming from site updates during the extraction process. This method also offers an additional benefit: it allows easy access to the data in its original form, which is crucial if reprocessing is needed.\n",
    "\n",
    "In the next step, we will focus on extracting the necessary information from the `html` pages, which is essential for conducting the analysis."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
