{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "558XhVVXfGK8"
   },
   "source": [
    "# Introduction\n",
    "\n",
    "The purpose of this task is to extract and save information about hockey teams into JSON format, based on data from files located in the `/data/raw` directory, which were generated in the previous stage. The information to be scraped and saved includes:  \n",
    "\n",
    "- Team Name (`Team Name`),  \n",
    "- Year (`Year`),  \n",
    "- Number of wins (`Wins`),  \n",
    "- Number of losses (`Losses`),  \n",
    "- Number of overtime losses (`OT Losses` - Overtime Losses),  \n",
    "- Win percentage (`Win %`),  \n",
    "- Number of goals scored (`Goals For (GF)`),  \n",
    "- Number of goals conceded (`Goals Against (GA)`),  \n",
    "- Goal differential (`+ / -`).  \n",
    "\n",
    "Each collected record should be organized into a dictionary with the structure shown below and then added to the results list:  \n",
    "\n",
    "```python  \n",
    "{  \n",
    "    'Team Name': 'Boston Bruins',  \n",
    "    'Year': '1990',  \n",
    "    'Wins': '44',  \n",
    "    'Losses': '24',  \n",
    "    'OT Losses': '',  \n",
    "    'Win %': '0.55',  \n",
    "    'Goals For (GF)': '299',  \n",
    "    'Goals Against (GA)': '264',  \n",
    "    '+ / -': '35'  \n",
    "}  \n",
    "```\n",
    "\n",
    "Place each item into the results list.\n",
    "\n",
    "The resulting data should be saved in a file named hockey_teams.json, which will be placed in the `data/interim/` folder. This file will serve as a data source for further analysis in the next part of the workshop.\n",
    "\n",
    "> At this point, converting HTML to JSON may seem complex and unnecessary, but it aims to consolidate knowledge regarding this data structure due to its universality and prevalence not only in the world of data analysis but generally in IT as well.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6u5hG5rOfGK_"
   },
   "source": [
    "# Notebook Configuration\n",
    "\n",
    "## Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "lVWklch6fGLA"
   },
   "outputs": [],
   "source": [
    "import bs4\n",
    "import json\n",
    "\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E37pRB3JfGLA"
   },
   "source": [
    "# Scraping\n",
    "\n",
    "To scrape the required information from the saved files, follow these steps:\n",
    "\n",
    "1. Find all HTML files in the `data/raw` folder using the `glob` module.\n",
    "2. For each HTML file, use `BeautifulSoup` to scrape the page and extract the needed data.\n",
    "3. Save the obtained data as partially processed in the `hockey_teams.json` file located in the `/data/interim/` folder.\n",
    "\n",
    "These steps will allow for efficient processing of data from HTML files and prepare them for further analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oxAHWKh7fGLB"
   },
   "source": [
    "## List of HTML files\n",
    "\n",
    "Using the `glob` module, find all `html` files in the `data/raw` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Kd6AfGWsfGLB"
   },
   "outputs": [],
   "source": [
    "files = glob('../data/raw/*.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZigRm-unfGLB"
   },
   "source": [
    "## Scraping\n",
    "\n",
    "Extract data from `html` files, making sure to maintain the expected structure of a single record:\n",
    "\n",
    "```python\n",
    "{\n",
    "    'Team Name': 'Boston Bruins',\n",
    "    'Year': '1990',\n",
    "    'Wins': '44',\n",
    "    'Losses': '24',\n",
    "    'OT Losses': '',\n",
    "    'Win %': '0.55',\n",
    "    'Goals For (GF)': '299',\n",
    "    'Goals Against (GA)': '264',\n",
    "    '+ / -': '35'\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ZWNiTH61fGLB"
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "for file in files:\n",
    "    with open(file) as f:\n",
    "        soup = bs4.BeautifulSoup(f.read(), 'html.parser')\n",
    "\n",
    "    table = soup.find('table')\n",
    "    header = [cell.text.strip() for cell in table.find_all('th')]\n",
    "\n",
    "    for row in table.find_all('tr', class_='team'):\n",
    "        cells = row.find_all('td')\n",
    "        cells = [cell.text.strip() for cell in cells]\n",
    "\n",
    "        record = dict(zip(header, cells))\n",
    "        data.append(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "4Ls8zhgBfKv_"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Team Name': 'Boston Bruins',\n",
       " 'Year': '1990',\n",
       " 'Wins': '44',\n",
       " 'Losses': '24',\n",
       " 'OT Losses': '',\n",
       " 'Win %': '0.55',\n",
       " 'Goals For (GF)': '299',\n",
       " 'Goals Against (GA)': '264',\n",
       " '+ / -': '35'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "96tkK70QfGLB"
   },
   "source": [
    "# Summary\n",
    "\n",
    "After extracting the relevant information, the final step in preparation for analysis is to save the data to disk.\n",
    "\n",
    "### Saving the file\n",
    "Here, save the data to `data/interim/` and name the file `hockey_teams.json`\n",
    "\n",
    "> Note: Remember to import the appropriate library for handling the JSON format beforehand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "VY4qaMYpfGLC"
   },
   "outputs": [],
   "source": [
    "with open('../data/interim/hockey_teams.json', 'w') as f:\n",
    "    json.dump(data, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
